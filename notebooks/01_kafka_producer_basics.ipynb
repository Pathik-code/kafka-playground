{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Producer Basics\n",
    "\n",
    "This notebook demonstrates how to create and use Kafka producers to send messages to topics.\n",
    "\n",
    "## Topics Covered:\n",
    "- Connecting to Kafka cluster\n",
    "- Creating a simple producer\n",
    "- Sending synchronous messages\n",
    "- Sending asynchronous messages with callbacks\n",
    "- Error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from kafka import KafkaProducer\n",
    "from kafka.errors import KafkaError\n",
    "\n",
    "# Kafka cluster connection\n",
    "KAFKA_SERVERS = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'kafka1:29092,kafka2:29093,kafka3:29094')\n",
    "print(f\"Connecting to Kafka at: {KAFKA_SERVERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Simple Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create producer with JSON serialization\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_SERVERS.split(','),\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "    key_serializer=lambda k: k.encode('utf-8') if k else None,\n",
    "    acks='all',  # Wait for all replicas to acknowledge\n",
    "    retries=3,\n",
    "    max_in_flight_requests_per_connection=1\n",
    ")\n",
    "\n",
    "print(\"✓ Producer created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Send Messages Synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = 'test-topic'\n",
    "\n",
    "# Send a single message\n",
    "message = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'message': 'Hello from Kafka Playground!',\n",
    "    'type': 'test'\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send synchronously and wait for acknowledgment\n",
    "    future = producer.send(topic_name, value=message, key='msg-1')\n",
    "    record_metadata = future.get(timeout=10)\n",
    "    \n",
    "    print(f\"✓ Message sent successfully!\")\n",
    "    print(f\"  Topic: {record_metadata.topic}\")\n",
    "    print(f\"  Partition: {record_metadata.partition}\")\n",
    "    print(f\"  Offset: {record_metadata.offset}\")\n",
    "except KafkaError as e:\n",
    "    print(f\"✗ Error sending message: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Send Multiple Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send 10 messages\n",
    "for i in range(10):\n",
    "    message = {\n",
    "        'id': i,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'data': f'Message number {i}',\n",
    "        'value': i * 10\n",
    "    }\n",
    "    \n",
    "    future = producer.send(topic_name, value=message, key=f'msg-{i}')\n",
    "    record_metadata = future.get(timeout=10)\n",
    "    print(f\"Sent message {i} to partition {record_metadata.partition} at offset {record_metadata.offset}\")\n",
    "    \n",
    "    time.sleep(0.1)  # Small delay\n",
    "\n",
    "print(\"\\n✓ All messages sent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Asynchronous Sending with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback functions\n",
    "def on_send_success(record_metadata):\n",
    "    print(f\"✓ Success! Topic: {record_metadata.topic}, Partition: {record_metadata.partition}, Offset: {record_metadata.offset}\")\n",
    "\n",
    "def on_send_error(excp):\n",
    "    print(f\"✗ Error: {excp}\")\n",
    "\n",
    "# Send messages asynchronously\n",
    "for i in range(5):\n",
    "    message = {\n",
    "        'id': i,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'message': f'Async message {i}'\n",
    "    }\n",
    "    \n",
    "    producer.send(topic_name, value=message).add_callback(on_send_success).add_errback(on_send_error)\n",
    "\n",
    "# Flush to ensure all messages are sent\n",
    "producer.flush()\n",
    "print(\"\\n✓ All async messages flushed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Send to Specific Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send message to a specific partition\n",
    "message = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'message': 'Message for partition 0'\n",
    "}\n",
    "\n",
    "future = producer.send(topic_name, value=message, partition=0)\n",
    "record_metadata = future.get(timeout=10)\n",
    "\n",
    "print(f\"✓ Sent to partition: {record_metadata.partition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Sending for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a producer optimized for batching\n",
    "batch_producer = KafkaProducer(\n",
    "    bootstrap_servers=KAFKA_SERVERS.split(','),\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "    batch_size=16384,  # Batch size in bytes\n",
    "    linger_ms=10,      # Wait up to 10ms to batch messages\n",
    "    compression_type='gzip'\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Send 100 messages in batch\n",
    "for i in range(100):\n",
    "    message = {\n",
    "        'id': i,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'data': f'Batch message {i}'\n",
    "    }\n",
    "    batch_producer.send(topic_name, value=message)\n",
    "\n",
    "batch_producer.flush()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Sent 100 messages in {elapsed:.2f} seconds\")\n",
    "print(f\"  Throughput: {100/elapsed:.2f} messages/second\")\n",
    "\n",
    "batch_producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the producer\n",
    "producer.close()\n",
    "print(\"✓ Producer closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **acks='all'**: Ensures all replicas acknowledge (most durable)\n",
    "2. **Batching**: Improves throughput significantly\n",
    "3. **Compression**: Reduces network bandwidth\n",
    "4. **Async sending**: Better performance for high-throughput scenarios\n",
    "5. **Partitioning**: Messages with same key go to same partition\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try the Consumer notebook (02_kafka_consumer_basics.ipynb) to read these messages!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
